#+TITLE: README
#+AUTHOR: Wei Sun (孙伟)
#+EMAIL: wei.sun@hexintek.com
#+DATE: <2021-09-23 四>
#+CATEGORY:
#+FILETAGS:

* README

由于 dnnl 的 bug, 测试时需要打一个 patch.

另外, dnnl json runtime 可以用 c++ 跑, dnnl c_src runtime 可以用 c 跑. 如果想用
c++ 跑 dnnl c_src runtime, 还需要另一个 patch

#+begin_example
  5 files changed, 46 insertions(+), 35 deletions(-)
  python/tvm/relay/op/contrib/dnnl.py           |  8 +++---
  src/relay/backend/contrib/dnnl/codegen.cc     |  9 +++++--
  src/runtime/contrib/dnnl/dnnl.cc              | 37 +++++++++++++++------------
  src/runtime/contrib/dnnl/dnnl_json_runtime.cc | 12 ++++-----
  src/runtime/contrib/dnnl/dnnl_kernel.h        | 15 ++++++-----

  modified   python/tvm/relay/op/contrib/dnnl.py
  @@ -62,10 +62,10 @@ def _register_external_op_helper(op_name, supported=True):
   _register_external_op_helper("nn.batch_norm")
   _register_external_op_helper("nn.conv2d")
   _register_external_op_helper("nn.dense")
  -_register_external_op_helper("nn.relu")
  -_register_external_op_helper("add")
  -_register_external_op_helper("subtract")
  -_register_external_op_helper("multiply")
  +# _register_external_op_helper("nn.relu")
  +# _register_external_op_helper("add")
  +# _register_external_op_helper("subtract")
  +# _register_external_op_helper("multiply")
 
 
   def make_pattern(with_bias=True):
  modified   src/relay/backend/contrib/dnnl/codegen.cc
  @@ -67,11 +67,13 @@ std::vector<std::string> Conv2d(const CallNode* call) {
       args.push_back(std::to_string(s));
     }
 
  -  // Args: O, G, Ph, Pw, Kh, Kw, Sh, Sw
  +  // Args: O, G, Ph0, Pw0, Ph1, Pw1, Kh, Kw, Sh, Sw
     args.push_back(std::to_string(wshape[0]));
     args.push_back(std::to_string(conv2d_attr->groups));
     args.push_back(std::to_string(conv2d_attr->padding[0].as<IntImmNode>()->value));
     args.push_back(std::to_string(conv2d_attr->padding[1].as<IntImmNode>()->value));
  +  args.push_back(std::to_string(conv2d_attr->padding[2].as<IntImmNode>()->value));
  +  args.push_back(std::to_string(conv2d_attr->padding[3].as<IntImmNode>()->value));
     args.push_back(std::to_string(wshape[2]));
     args.push_back(std::to_string(wshape[3]));
     args.push_back(std::to_string(conv2d_attr->strides[0].as<IntImmNode>()->value));
  @@ -367,10 +369,12 @@ class DNNLModuleCodegen : public CSourceModuleCodegenBase {
 
       // Record the external symbol for runtime lookup.
       auto sid = GetExtSymbol(func);
  -
       CodegenDNNL builder(sid);
       auto out = builder.VisitExpr(func->body);
       code_stream_ << builder.JIT(out);
  +    code_stream_ << "static int " << sid << "_reg_ = "
  +                 << "TVMBackendRegisterSystemLibSymbol (\"" << sid << "\", (void *) " << sid
  +                 << ");\n";
 
       return {sid, builder.const_vars_};
     }
  @@ -393,6 +397,7 @@ class DNNLModuleCodegen : public CSourceModuleCodegenBase {
       code_stream_ << "#include <cstring>\n";
       code_stream_ << "#include <vector>\n";
       code_stream_ << "#include <tvm/runtime/c_runtime_api.h>\n";
  +    code_stream_ << "#include <tvm/runtime/c_backend_api.h>\n";
       code_stream_ << "#include <tvm/runtime/packed_func.h>\n";
       code_stream_ << "#include <dlpack/dlpack.h>\n";
       // dnnl_kernel file is saved under src/runtime/contrib/dnnl so that we don't
  modified   src/runtime/contrib/dnnl/dnnl.cc
  @@ -53,8 +53,9 @@ inline void read_from_dnnl_memory(void* handle, const memory& mem) {
   }
 
   void dnnl_conv2d_common(float* data, float* weights, float* bias, float* out, int p_N_, int p_C_,
  -                        int p_H_, int p_W_, int p_O_, int p_G_, int p_Ph_, int p_Pw_, int p_Kh_,
  -                        int p_Kw_, int p_Sh_, int p_Sw_, primitive_attr attr) {
  +                        int p_H_, int p_W_, int p_O_, int p_G_, int p_Ph0_, int p_Pw0_, int p_Ph1_,
  +                        int p_Pw1_, int p_Kh_, int p_Kw_, int p_Sh_, int p_Sw_,
  +                        primitive_attr attr) {
     using tag = memory::format_tag;
     using dt = memory::data_type;
     engine eng(engine::kind::cpu, 0);
  @@ -64,10 +65,11 @@ void dnnl_conv2d_common(float* data, float* weights, float* bias, float* out, in
     memory::dims conv2d_weights_tz = {p_O_, p_C_, p_Kh_, p_Kw_};
     if (p_G_ > 1) conv2d_weights_tz = {p_G_, 1, p_C_ / p_G_, p_Kh_, p_Kw_};
     memory::dims conv2d_bias_tz = {p_O_};
  -  memory::dims conv2d_dst_tz = {p_N_, p_O_, (p_H_ - p_Kh_ + 2 * p_Ph_ + p_Sh_) / p_Sh_,
  -                                (p_W_ - p_Kw_ + 2 * p_Pw_ + p_Sw_) / p_Sw_};
  +  memory::dims conv2d_dst_tz = {p_N_, p_O_, (p_H_ - p_Kh_ + p_Ph0_ + p_Ph1_ + p_Sh_) / p_Sh_,
  +                                (p_W_ - p_Kw_ + p_Pw0_ + p_Pw1_ + p_Sw_) / p_Sw_};
     memory::dims conv2d_strides = {p_Sh_, p_Sw_};
  -  memory::dims conv2d_padding = {p_Ph_, p_Pw_};
  +  memory::dims conv2d_padding0 = {p_Ph0_, p_Pw0_};
  +  memory::dims conv2d_padding1 = {p_Ph1_, p_Pw1_};
 
     auto user_src_memory = memory({{conv2d_src_tz}, dt::f32, tag::nchw}, eng, data);
     auto user_weights_memory =
  @@ -81,7 +83,7 @@ void dnnl_conv2d_common(float* data, float* weights, float* bias, float* out, in
 
     auto conv2d_desc = convolution_forward::desc(
         prop_kind::forward_inference, algorithm::convolution_direct, conv2d_src_md, conv2d_weights_md,
  -      conv2d_bias_md, conv2d_dst_md, conv2d_strides, conv2d_padding, conv2d_padding);
  +      conv2d_bias_md, conv2d_dst_md, conv2d_strides, conv2d_padding0, conv2d_padding1);
     auto conv2d_prim_desc = convolution_forward::primitive_desc(conv2d_desc, attr, eng);
 
     auto conv2d_src_memory = user_src_memory;
  @@ -98,12 +100,12 @@ void dnnl_conv2d_common(float* data, float* weights, float* bias, float* out, in
   }
 
   extern "C" void dnnl_conv2d(float* data, float* weights, float* out, int p_N_, int p_C_, int p_H_,
  -                            int p_W_, int p_O_, int p_G_, int p_Ph_, int p_Pw_, int p_Kh_,
  -                            int p_Kw_, int p_Sh_, int p_Sw_) {
  +                            int p_W_, int p_O_, int p_G_, int p_Ph0_, int p_Pw0_, int p_Ph1_,
  +                            int p_Pw1_, int p_Kh_, int p_Kw_, int p_Sh_, int p_Sw_) {
     primitive_attr attr;
     std::vector<float> bias(p_O_, 0);
     return dnnl_conv2d_common(data, weights, bias.data(), out, p_N_, p_C_, p_H_, p_W_, p_O_, p_G_,
  -                            p_Ph_, p_Pw_, p_Kh_, p_Kw_, p_Sh_, p_Sw_, attr);
  +                            p_Ph0_, p_Pw0_, p_Ph1_, p_Pw1_, p_Kh_, p_Kw_, p_Sh_, p_Sw_, attr);
   }
 
   primitive_attr create_attr_with_relu_post_op() {
  @@ -117,20 +119,23 @@ primitive_attr create_attr_with_relu_post_op() {
   }
 
   extern "C" void dnnl_fused_conv2d_relu(float* data, float* weights, float* out, int p_N_, int p_C_,
  -                                       int p_H_, int p_W_, int p_O_, int p_G_, int p_Ph_, int p_Pw_,
  -                                       int p_Kh_, int p_Kw_, int p_Sh_, int p_Sw_) {
  +                                       int p_H_, int p_W_, int p_O_, int p_G_, int p_Ph0_,
  +                                       int p_Pw0_, int p_Ph1_, int p_Pw1_, int p_Kh_, int p_Kw_,
  +                                       int p_Sh_, int p_Sw_) {
     std::vector<float> bias(p_O_, 0);
     return dnnl_conv2d_common(data, weights, bias.data(), out, p_N_, p_C_, p_H_, p_W_, p_O_, p_G_,
  -                            p_Ph_, p_Pw_, p_Kh_, p_Kw_, p_Sh_, p_Sw_,
  +                            p_Ph0_, p_Pw0_, p_Ph1_, p_Pw1_, p_Kh_, p_Kw_, p_Sh_, p_Sw_,
                               create_attr_with_relu_post_op());
   }
 
   extern "C" void dnnl_fused_conv2d_bias_relu(float* data, float* weights, float* bias, float* out,
                                               int p_N_, int p_C_, int p_H_, int p_W_, int p_O_,
  -                                            int p_G_, int p_Ph_, int p_Pw_, int p_Kh_, int p_Kw_,
  -                                            int p_Sh_, int p_Sw_) {
  -  return dnnl_conv2d_common(data, weights, bias, out, p_N_, p_C_, p_H_, p_W_, p_O_, p_G_, p_Ph_,
  -                            p_Pw_, p_Kh_, p_Kw_, p_Sh_, p_Sw_, create_attr_with_relu_post_op());
  +                                            int p_G_, int p_Ph0_, int p_Pw0_, int p_Ph1_,
  +                                            int p_Pw1_, int p_Kh_, int p_Kw_, int p_Sh_,
  +                                            int p_Sw_) {
  +  return dnnl_conv2d_common(data, weights, bias, out, p_N_, p_C_, p_H_, p_W_, p_O_, p_G_, p_Ph0_,
  +                            p_Pw0_, p_Ph1_, p_Pw1_, p_Kh_, p_Kw_, p_Sh_, p_Sw_,
  +                            create_attr_with_relu_post_op());
   }
 
   extern "C" void dnnl_dense(float* data, float* weight, float* out, int p_B_, int p_I_, int p_O_) {
  modified   src/runtime/contrib/dnnl/dnnl_json_runtime.cc
  @@ -163,16 +163,16 @@ class DNNLJSONRuntime : public JSONRuntimeBase {
       dnnl::memory::dim N = input_shape[0],       // batch size
           IC = input_shape[1],                    // input channels
           IH = input_shape[2],                    // input height
  -        IW = input_shape[2],                    // input width
  +        IW = input_shape[3],                    // input width
           OC = weight_shape[0],                   // output channels
           KH = weight_shape[2],                   // weight height
           KW = weight_shape[3],                   // weight width
  -        PH_L = std::stoi(str_padding[1]),       // height padding: left
  -        PH_R = std::stoi(str_padding[3]),       // height padding: right
  -        PW_L = std::stoi(str_padding[0]),       // width padding: left
  -        PW_R = std::stoi(str_padding[2]),       // width padding: right
  +        PW_L = std::stoi(str_padding[1]),       // width padding: left
  +        PW_R = std::stoi(str_padding[3]),       // width padding: right
  +        PH_L = std::stoi(str_padding[0]),       // height padding: top
  +        PH_R = std::stoi(str_padding[2]),       // height padding: bottom
           SH = std::stoi(str_strides[0]),         // height-wise stride
  -        SW = std::stoi(str_strides[0]),         // weight-wise stride
  +        SW = std::stoi(str_strides[1]),         // weight-wise stride
           OH = (IH - KH + PH_L + PH_R) / SH + 1,  // output height
           OW = (IW - KW + PW_L + PW_R) / SW + 1;  // output width
 
  modified   src/runtime/contrib/dnnl/dnnl_kernel.h
  @@ -36,19 +36,20 @@ namespace contrib {
   using namespace dnnl;
 
   extern "C" TVM_DLL void dnnl_conv2d(float* data, float* weights, float* out, int p_N_, int p_C_,
  -                                    int p_H_, int p_W_, int p_O_, int p_G_, int p_Ph_, int p_Pw_,
  -                                    int p_Kh_, int p_Kw_, int p_Sh_, int p_Sw_);
  +                                    int p_H_, int p_W_, int p_O_, int p_G_, int p_Ph0_, int p_Pw0_,
  +                                    int p_Ph1_, int p_Pw1_, int p_Kh_, int p_Kw_, int p_Sh_,
  +                                    int p_Sw_);
 
   extern "C" TVM_DLL void dnnl_fused_conv2d_relu(float* data, float* weights, float* out, int p_N_,
                                                  int p_C_, int p_H_, int p_W_, int p_O_, int p_G_,
  -                                               int p_Ph_, int p_Pw_, int p_Kh_, int p_Kw_,
  -                                               int p_Sh_, int p_Sw_);
  +                                               int p_Ph0_, int p_Pw0_, int p_Ph1_, int p_Pw1_,
  +                                               int p_Kh_, int p_Kw_, int p_Sh_, int p_Sw_);
 
   extern "C" TVM_DLL void dnnl_fused_conv2d_bias_relu(float* data, float* weights, float* bias,
                                                       float* out, int p_N_, int p_C_, int p_H_,
  -                                                    int p_W_, int p_O_, int p_G_, int p_Ph_,
  -                                                    int p_Pw_, int p_Kh_, int p_Kw_, int p_Sh_,
  -                                                    int p_Sw_);
  +                                                    int p_W_, int p_O_, int p_G_, int p_Ph0_,
  +                                                    int p_Pw0_, int p_Ph1_, int p_Pw1_, int p_Kh_,
  +                                                    int p_Kw_, int p_Sh_, int p_Sw_);
 
   extern "C" TVM_DLL void dnnl_dense(float* data, float* weight, float* out, int p_B_, int p_I_,
                                      int p_O_);



#+end_example
