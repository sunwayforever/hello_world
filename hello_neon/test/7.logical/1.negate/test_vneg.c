// 2023-04-20 16:37
#include <neon.h>
#include <neon_test.h>
// int8x8_t vneg_s8(int8x8_t a)
// int16x4_t vneg_s16(int16x4_t a)
// int32x2_t vneg_s32(int32x2_t a)
// float32x2_t vneg_f32(float32x2_t a)
// int64x1_t vneg_s64(int64x1_t a)
//
// int8x16_t vnegq_s8(int8x16_t a)
// int16x8_t vnegq_s16(int16x8_t a)
// int32x4_t vnegq_s32(int32x4_t a)
// float32x4_t vnegq_f32(float32x4_t a)
// -------------------------------------
// int64_t vnegd_s64(int64_t a)
// float64x1_t vneg_f64(float64x1_t a)
//
// int64x2_t vnegq_s64(int64x2_t a)
// float64x2_t vnegq_f64(float64x2_t a)

TEST_CASE(test_vnegq_s8) {
    static const struct {
        int8_t a[16];
        int8_t r[16];
    } test_vec[] = {
        {{33, -124, 14, -53, -28, -98, -12, 95, -17, 54, 88, 35, 84, 68, 14,
          -64},
         {-33, 124, -14, 53, 28, 98, 12, -95, 17, -54, -88, -35, -84, -68, -14,
          64}},
        {{93, 100, INT8_MIN, -18, -20, 22, -77, -95, 14, 36, 106, 50, -110, 71,
          -18, -77},
         {-93, -100, INT8_MIN, 18, 20, -22, 77, 95, -14, -36, -106, -50, 110,
          -71, 18, 77}},
        {{-53, -4, INT8_MAX, -81, -101, 115, 14, -118, -86, 103, -82, -2, -85,
          -68, -66, 9},
         {53, 4, -127, 81, 101, -115, -14, 118, 86, -103, 82, 2, 85, 68, 66,
          -9}},
        {{32, 63, -9, 13, 85, -86, -82, 99, -49, 24, -106, 97, 95, -124, 20,
          43},
         {-32, -63, 9, -13, -85, 86, 82, -99, 49, -24, 106, -97, -95, 124, -20,
          -43}},
        {{-127, -109, -38, 28, 7, -23, -90, -79, 80, 84, -81, -5, 16, 110, 4,
          49},
         {INT8_MAX, 109, 38, -28, -7, 23, 90, 79, -80, -84, 81, 5, -16, -110,
          -4, -49}},
        {{-83, -5, 62, 2, -90, -20, 102, 117, 4, -4, -42, 100, INT8_MIN, -22,
          -113, 1},
         {83, 5, -62, -2, 90, 20, -102, -117, -4, 4, 42, -100, INT8_MIN, 22,
          113, -1}},
        {{126, 105, 29, -123, 82, -60, 54, -94, 24, -27, -98, 41, 83, -94, 90,
          0},
         {-126, -105, -29, 123, -82, 60, -54, 94, -24, 27, 98, -41, -83, 94,
          -90, 0}},
        {{-98, -104, 3, 68, -124, 105, -71, -120, 101, -113, -20, -27, 121, 123,
          -25, -9},
         {98, 104, -3, -68, 124, -105, 71, 120, -101, 113, 20, 27, -121, -123,
          25, 9}}};

    for (size_t i = 0; i < (sizeof(test_vec) / sizeof(test_vec[0])); i++) {
        int8x16_t a = vld1q_s8(test_vec[i].a);
        int8x16_t r = vnegq_s8(a);
        int8x16_t check = vld1q_s8(test_vec[i].r);
        ASSERT_EQUAL(r, check);
    }
    return 0;
}
