// 2023-04-14 10:44
#include <neon.h>
#include <neon_test.h>
/* NOTE: add 的结果会有右移, 所以称为 narrowing 指令 */

// int8x8_t vhadd_s8(int8x8_t a,int8x8_t b)
//           ^--- half, r[i]=(a[i]+b[i])>>1
// int16x4_t vhadd_s16(int16x4_t a,int16x4_t b)
// int32x2_t vhadd_s32(int32x2_t a,int32x2_t b)
// uint8x8_t vhadd_u8(uint8x8_t a,uint8x8_t b)
// uint16x4_t vhadd_u16(uint16x4_t a,uint16x4_t b)
// uint32x2_t vhadd_u32(uint32x2_t a,uint32x2_t b)
//
// uint8x16_t vhaddq_u8(uint8x16_t a,uint8x16_t b)
// uint16x8_t vhaddq_u16(uint16x8_t a,uint16x8_t b)
// uint32x4_t vhaddq_u32(uint32x4_t a,uint32x4_t b)
// int8x16_t vhaddq_s8(int8x16_t a,int8x16_t b)
// int16x8_t vhaddq_s16(int16x8_t a,int16x8_t b)
// int32x4_t vhaddq_s32(int32x4_t a,int32x4_t b)
// ------------------------------------------------
// int8x8_t vrhadd_s8(int8x8_t a,int8x8_t b)
//           ^--- rounding, r[i]=(a[i]+b[i]+1)>>1
// int16x4_t vrhadd_s16(int16x4_t a,int16x4_t b)
// int32x2_t vrhadd_s32(int32x2_t a,int32x2_t b)
// uint8x8_t vrhadd_u8(uint8x8_t a,uint8x8_t b)
// uint16x4_t vrhadd_u16(uint16x4_t a,uint16x4_t b)
// uint32x2_t vrhadd_u32(uint32x2_t a,uint32x2_t b)
//
// int8x16_t vrhaddq_s8(int8x16_t a,int8x16_t b)
// int16x8_t vrhaddq_s16(int16x8_t a,int16x8_t b)
// int32x4_t vrhaddq_s32(int32x4_t a,int32x4_t b)
// uint8x16_t vrhaddq_u8(uint8x16_t a,uint8x16_t b)
// uint16x8_t vrhaddq_u16(uint16x8_t a,uint16x8_t b)
// uint32x4_t vrhaddq_u32(uint32x4_t a,uint32x4_t b)
// ------------------------------------------------
// int8x8_t vaddhn_s16(int16x8_t a,int16x8_t b)
//              ^^--- high narrow, r[i]=(a[i]+b[i])>>8
// int16x4_t vaddhn_s32(int32x4_t a,int32x4_t b)
// int32x2_t vaddhn_s64(int64x2_t a,int64x2_t b)
// uint8x8_t vaddhn_u16(uint16x8_t a,uint16x8_t b)
// uint16x4_t vaddhn_u32(uint32x4_t a,uint32x4_t b)
// uint32x2_t vaddhn_u64(uint64x2_t a,uint64x2_t b)
// ------------------------------------------------
// int8x8_t vraddhn_s16(int16x8_t a,int16x8_t b)
//           ^--- round, r[i]=(a[i]+b[i]+1<<7)>>8
// int16x4_t vraddhn_s32(int32x4_t a,int32x4_t b)
// int32x2_t vraddhn_s64(int64x2_t a,int64x4_t b)
// uint8x8_t vraddhn_u16(uint16x8_t a,uint16x8_t b)
// uint16x4_t vraddhn_u32(uint32x4_t a,uint32x4_t b)
// uint32x2_t vraddhn_u64(uint64x2_t a,uint64x2_t b)
//
TEST_CASE(test_vaddhn_s16) {
    static const struct {
        int16_t a[8];
        int16_t b[8];
        int8_t r[8];
    } test_vec[] = {
        {{10191, 527, -15725, -15434, -29291, -21715, -19795, 69},
         {-17904, -30996, 15212, -23888, -18775, 22323, -6945, -20945},
         {-31, -120, -3, 102, 68, 2, -105, -82}},
        {{15884, -24656, 26369, -27038, -28428, -23998, -30910, 21154},
         {-29119, -21032, -30263, 29264, -31937, 7881, -1944, 29901},
         {-52, 77, -16, 8, 20, -63, INT8_MAX, -57}},
        {{32055, 14355, 30180, -9778, 4101, 18555, 7575, -10086},
         {29611, 29830, -10500, 15335, -20391, -16038, 10153, -8139},
         {-16, -84, 76, 21, -64, 9, 69, -72}},
        {{18596, -30440, -6466, -15518, -8713, -29173, -22790, -23193},
         {-4839, 5401, 195, 7248, -21839, 23262, 5073, 30266},
         {53, -98, -25, -33, -120, -24, -70, 27}},
        {{21084, 6911, 24888, 12253, -5826, 14526, 9615, -22307},
         {-2542, -10819, 3575, -22287, -12360, -30462, 15587, 16383},
         {72, -16, 111, -40, -72, -63, 98, -24}},
        {{-370, -14759, 13919, -25098, -19425, -20779, -19751, -5290},
         {5033, -24384, -20191, -9912, 19073, 25698, 25222, 5283},
         {18, 103, -25, 119, -2, 19, 21, -1}},
        {{-928, -16166, -12238, 21085, 13188, 23808, 22501, -29112},
         {2154, -29906, 30394, 15204, -14400, 18079, 16937, -30374},
         {4, 76, 70, -115, -5, -93, -102, 23}},
        {{13630, 28745, -22779, -30014, -15398, -16409, 12314, -31666},
         {31800, -3568, 29939, -19667, -13253, 25850, 21518, 19694},
         {-79, 98, 27, 61, -112, 36, -124, -47}}};

    for (size_t i = 0; i < (sizeof(test_vec) / sizeof(test_vec[0])); i++) {
        int16x8_t a = vld1q_s16(test_vec[i].a);
        int16x8_t b = vld1q_s16(test_vec[i].b);
        int8x8_t r = vaddhn_s16(a, b);
        int8x8_t check = vld1_s8(test_vec[i].r);
        ASSERT_EQUAL(r, check);
    }
    return 0;
}

/* NOTE: vhadd 的 h 前缀表示 half, 计算 (a+b)>>1, vhadd 支持 {s,u}{8,16,32},
 * 支持 q 后缀, 不支持 float */
TEST_CASE(test_vhadd_s8) {
    static const struct {
        int8_t a[8];
        int8_t b[8];
        int8_t r[8];
    } test_vec[] = {
        {{-111, -110, 14, -92, -21, -15, -67, 34},
         {85, 113, 87, -58, 112, 51, -18, 103},
         {-13, 1, 50, -75, 45, 18, -43, 68}},
        {{119, -32, -32, -30, -5, -80, -127, 47},
         {-27, -10, -111, -68, 125, -43, -31, 14},
         {46, -21, -72, -49, 60, -62, -79, 30}},
        {{103, -17, -78, 83, -32, 112, 117, 53},
         {-31, -52, -4, 81, -1, -22, -72, 118},
         {36, -35, -41, 82, -17, 45, 22, 85}},
        {{-54, -104, 89, -59, 73, -38, -12, 46},
         {-48, -123, -22, 78, 90, -53, 92, -63},
         {-51, -114, 33, 9, 81, -46, 40, -9}},
        {{-70, 15, 20, -101, INT8_MAX, -119, -48, 96},
         {85, -52, -79, 84, -74, 106, -53, INT8_MIN},
         {7, -19, -30, -9, 26, -7, -51, -16}},
        {{2, 36, 69, 75, -2, 57, 121, -50},
         {-66, 99, 28, 24, 46, 121, -38, -23},
         {-32, 67, 48, 49, 22, 89, 41, -37}},
        {{-120, -18, -124, 7, 120, 84, 103, -51},
         {33, 24, 34, -41, -126, -19, 88, -123},
         {-44, 3, -45, -17, -3, 32, 95, -87}},
        {{17, -99, -48, 15, -41, 74, -35, -107},
         {-83, -6, -82, -36, 115, -120, -59, -5},
         {-33, -53, -65, -11, 37, -23, -47, -56}}};

    for (size_t i = 0; i < (sizeof(test_vec) / sizeof(test_vec[0])); i++) {
        int8x8_t a = vld1_s8(test_vec[i].a);
        int8x8_t b = vld1_s8(test_vec[i].b);
        int8x8_t r = vhadd_s8(a, b);
        int8x8_t check = vld1_s8(test_vec[i].r);
        ASSERT_EQUAL(r, check);
    }
    return 0;
}

/* NOTE: vrhadd 的 rh 前缀表示 round half, 其它与 vhadd 相同 */
TEST_CASE(test_vrhadd_s8) {
    static const struct {
        int8_t a[8];
        int8_t b[8];
        int8_t r[8];
    } test_vec[] = {
        {{36, -29, -56, 59, -57, -47, 80, -118},
         {67, 70, 3, -93, 56, -95, -31, -57},
         {52, 21, -26, -17, 0, -71, 25, -87}},
        {{122, -28, 39, -51, 36, 123, -105, -67},
         {-33, 123, -90, -110, -50, -124, -64, -14},
         {45, 48, -25, -80, -7, 0, -84, -40}},
        {{103, -119, 45, 46, 90, 125, -72, -99},
         {-61, -69, 64, -5, 92, 34, -62, -42},
         {21, -94, 55, 21, 91, 80, -67, -70}},
        {{6, -22, -92, 42, 101, 59, -25, 68},
         {-74, -114, -42, -124, 18, -105, 119, 121},
         {-34, -68, -67, -41, 60, -23, 47, 95}},
        {{32, -92, -89, 122, 34, 96, 24, -27},
         {27, 88, -31, 120, 122, -93, 78, -127},
         {30, -2, -60, 121, 78, 2, 51, -77}},
        {{-115, -14, -85, -13, 45, -109, 55, -29},
         {33, 14, 104, 51, -91, -33, -84, -59},
         {-41, 0, 10, 19, -23, -71, -14, -44}},
        {{-125, 83, 63, -91, -77, 87, -117, -49},
         {-80, 108, 71, 42, 15, -107, -85, -99},
         {-102, 96, 67, -24, -31, -10, -101, -74}},
        {{-120, 87, -112, -75, -22, -57, -103, 11},
         {-43, 1, 62, 122, -32, -22, 63, 99},
         {-81, 44, -25, 24, -27, -39, -20, 55}},

    };
    for (size_t i = 0; i < (sizeof(test_vec) / sizeof(test_vec[0])); i++) {
        int8x8_t a = vld1_s8(test_vec[i].a);
        int8x8_t b = vld1_s8(test_vec[i].b);
        int8x8_t r = vrhadd_s8(a, b);
        int8x8_t check = vld1_s8(test_vec[i].r);
        ASSERT_EQUAL(r, check);
    }
    return 0;
}
